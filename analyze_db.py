#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
- –ê–≤—Ç–æ-—Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ GPT
- –ü–æ–∏—Å–∫ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥—É–±–ª–µ–π
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –æ—Ç—á—ë—Ç—ã
"""

import sqlite3
import json
import sys
import re
from difflib import SequenceMatcher
import openai

DB_PATH = 'knowledge.db'
CONFIG_PATH = 'config.json'


def load_config():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞"""
    try:
        with open(CONFIG_PATH, 'r') as f:
            return json.load(f)
    except:
        print("‚ùå –ù–µ –º–æ–≥—É –∑–∞–≥—Ä—É–∑–∏—Ç—å config.json")
        sys.exit(1)


class DBAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, db_path, gpt_api_key):
        self.db_path = db_path
        openai.api_key = gpt_api_key
        self.model = "gpt-4o-mini"
    
    def get_all_records(self):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, question, answer, category, tags 
            FROM knowledge 
            WHERE is_current = 1
        ''')
        records = cursor.fetchall()
        conn.close()
        return records
    
    def analyze_record(self, question, answer):
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–ø–∏—Å–∏ —á–µ—Ä–µ–∑ GPT"""
        try:
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç: {answer}

–§–æ—Ä–º–∞—Ç (—Å—Ç—Ä–æ–≥–æ JSON, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞):
{{
  "category": "–∫–∞—Ç–µ–≥–æ—Ä–∏—è",
  "tags": "—Ç–µ–≥1,—Ç–µ–≥2,—Ç–µ–≥3,—Ç–µ–≥4,—Ç–µ–≥5"
}}

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:
- hardware (–∂–µ–ª–µ–∑–æ, –∫–æ–º–ø—å—é—Ç–µ—Ä—ã, –ø–µ—Ä–∏—Ñ–µ—Ä–∏—è, –±–∏–æ—Å, –º–∞—Ç –ø–ª–∞—Ç—ã)
- software (–ø—Ä–æ–≥—Ä–∞–º–º—ã, –û–°, –¥—Ä–∞–π–≤–µ—Ä–∞, —É—Ç–∏–ª–∏—Ç—ã, CLS)
- games (–∏–≥—Ä—ã, Steam, –ª–∞—É–Ω—á–µ—Ä—ã, –≥–µ–π–º–ø–ª–µ–π)
- service (—É—Å–ª—É–≥–∏ –∫–ª—É–±–∞, —Ü–µ–Ω—ã, –≤—Ä–µ–º—è, –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
- admin (–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–ª—É–±–æ–º)
- billing (–æ–ø–ª–∞—Ç–∞, —Å—á–µ—Ç–∞, —Ç–∞—Ä–∏—Ñ—ã, –∞–±–æ–Ω–µ–º–µ–Ω—Ç—ã)
- schedule (—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ, –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã, —á–∞—Å—ã)
- general (–≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ)

–¢–µ–≥–∏: 3-5 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Å—Ç—Ä–æ—á–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –ë–ï–ó –ø—Ä–æ–±–µ–ª–æ–≤."""

            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.3
            )
            
            text = response.choices[0].message.content.strip()
            
            # –ü–∞—Ä—Å–∏–º JSON
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = text[start:end]
                data = json.loads(json_str)
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                valid_cats = ['hardware', 'software', 'games', 'service', 'admin', 'billing', 'schedule', 'general']
                if data.get('category') not in valid_cats:
                    data['category'] = 'general'
                
                # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–≥–æ–≤
                tags = data.get('tags', '')
                tags = re.sub(r'\s+', '', tags)  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
                tags = ','.join(filter(None, tags.lower().split(',')))
                data['tags'] = tags[:200]
                
                return data
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        
        return {'category': 'general', 'tags': ''}
    
    def find_duplicates(self, records, threshold=0.80):
        """–ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        duplicates = []
        
        for i, (id1, q1, a1, cat1, tags1) in enumerate(records):
            for id2, q2, a2, cat2, tags2 in records[i+1:]:
                # –°—Ö–æ–¥—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
                q_sim = SequenceMatcher(None, q1.lower(), q2.lower()).ratio()
                
                # –°—Ö–æ–¥—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤
                a_sim = SequenceMatcher(None, a1.lower(), a2.lower()).ratio()
                
                # –û–±—â–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å (–≤–æ–ø—Ä–æ—Å –≤–∞–∂–Ω–µ–µ)
                similarity = q_sim * 0.7 + a_sim * 0.3
                
                if similarity >= threshold:
                    duplicates.append({
                        'id1': id1,
                        'id2': id2,
                        'question1': q1,
                        'question2': q2,
                        'similarity': round(similarity * 100, 1)
                    })
        
        return duplicates
    
    def update_record(self, id, category, tags):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                UPDATE knowledge 
                SET category = ?, tags = ?, updated_at = CURRENT_TIMESTAMP
                WHERE id = ?
            ''', (category, tags, id))
            conn.commit()
            conn.close()
            return True
        except:
            return False
    
    def merge_duplicates(self, id_keep, id_remove):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–≥–∏ –æ–±–µ–∏—Ö –∑–∞–ø–∏—Å–µ–π
            cursor.execute('SELECT tags FROM knowledge WHERE id IN (?, ?)', (id_keep, id_remove))
            tags_list = cursor.fetchall()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–≥–∏
            all_tags = set()
            for (tags,) in tags_list:
                if tags:
                    all_tags.update(tags.split(','))
            
            merged_tags = ','.join(sorted(filter(None, all_tags)))
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–ø–∏—Å—å
            cursor.execute('''
                UPDATE knowledge 
                SET tags = ?, updated_at = CURRENT_TIMESTAMP 
                WHERE id = ?
            ''', (merged_tags, id_keep))
            
            # –ü–æ–º–µ—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç –∫–∞–∫ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–π
            cursor.execute('''
                UPDATE knowledge 
                SET is_current = 0, updated_at = CURRENT_TIMESTAMP 
                WHERE id = ?
            ''', (id_remove,))
            
            conn.commit()
            conn.close()
            return True
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ merge: {e}")
            return False
    
    def get_stats(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        stats = {}
        
        # –í—Å–µ–≥–æ
        cursor.execute('SELECT COUNT(*) FROM knowledge WHERE is_current = 1')
        stats['total'] = cursor.fetchone()[0]
        
        # –ë–µ–∑ —Ç–µ–≥–æ–≤
        cursor.execute('SELECT COUNT(*) FROM knowledge WHERE is_current = 1 AND (tags = "" OR tags IS NULL)')
        stats['no_tags'] = cursor.fetchone()[0]
        
        # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        cursor.execute('SELECT category, COUNT(*) FROM knowledge WHERE is_current = 1 GROUP BY category')
        stats['by_category'] = dict(cursor.fetchall())
        
        # Legacy
        cursor.execute('SELECT COUNT(*) FROM knowledge WHERE is_current = 0')
        stats['legacy'] = cursor.fetchone()[0]
        
        conn.close()
        return stats


def main():
    print("üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π v3.0\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
    config = load_config()
    analyzer = DBAnalyzer(DB_PATH, config['openai_api_key'])
    
    # –ú–µ–Ω—é
    print("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
    print("1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (—á–µ—Ä–µ–∑ GPT)")
    print("2. –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    print("3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
    print("4. –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≤—Å—ë —Å—Ä–∞–∑—É)")
    print("5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    print("0. –í—ã—Ö–æ–¥")
    
    choice = input("\n–í—ã–±–æ—Ä: ").strip()
    
    if choice == '1':
        # –ê–≤—Ç–æ—Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        print("\n‚è≥ –ü–æ–ª—É—á–∞—é –∑–∞–ø–∏—Å–∏...")
        records = analyzer.get_all_records()
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç —Ç–µ–≥–æ–≤
        no_tags = [(id, q, a, cat, tags) for id, q, a, cat, tags in records if not tags]
        
        print(f"–ë–µ–∑ —Ç–µ–≥–æ–≤: {len(no_tags)}")
        
        if not no_tags:
            print("‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ —É–∂–µ –∏–º–µ—é—Ç —Ç–µ–≥–∏!")
            return
        
        confirm = input(f"\n–û–±—Ä–∞–±–æ—Ç–∞—Ç—å {len(no_tags)} –∑–∞–ø–∏—Å–µ–π —á–µ—Ä–µ–∑ GPT? (y/n): ")
        
        if confirm.lower() != 'y':
            print("–û—Ç–º–µ–Ω–µ–Ω–æ")
            return
        
        print("\n‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")
        
        success = 0
        for i, (id, q, a, cat, tags) in enumerate(no_tags, 1):
            print(f"[{i}/{len(no_tags)}] {q[:50]}...")
            
            analysis = analyzer.analyze_record(q, a)
            
            if analyzer.update_record(id, analysis['category'], analysis['tags']):
                success += 1
                print(f"  ‚Üí {analysis['category']} | {analysis['tags'][:50]}")
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {success}/{len(no_tags)}")
    
    elif choice == '2':
        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        print("\n‚è≥ –ò—â—É –¥—É–±–ª–∏–∫–∞—Ç—ã...")
        records = analyzer.get_all_records()
        
        duplicates = analyzer.find_duplicates(records, threshold=0.80)
        
        if not duplicates:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            return
        
        print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}\n")
        
        for i, dup in enumerate(duplicates[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10
            print(f"{i}. –°—Ö–æ–∂–µ—Å—Ç—å: {dup['similarity']}%")
            print(f"   ID1: {dup['id1']} | {dup['question1'][:60]}")
            print(f"   ID2: {dup['id2']} | {dup['question2'][:60]}")
            print()
        
        if len(duplicates) > 10:
            print(f"... –∏ –µ—â—ë {len(duplicates) - 10} –ø–∞—Ä")
    
    elif choice == '3':
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        print("\n‚è≥ –ò—â—É –∏ –æ–±—ä–µ–¥–∏–Ω—è—é –¥—É–±–ª–∏–∫–∞—Ç—ã...")
        records = analyzer.get_all_records()
        
        duplicates = analyzer.find_duplicates(records, threshold=0.85)
        
        if not duplicates:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            return
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(duplicates)}")
        
        confirm = input(f"\n–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏? (y/n): ")
        
        if confirm.lower() != 'y':
            print("–û—Ç–º–µ–Ω–µ–Ω–æ")
            return
        
        merged = 0
        for dup in duplicates:
            # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Å –º–µ–Ω—å—à–∏–º ID (–±–æ–ª–µ–µ —Å—Ç–∞—Ä—É—é)
            id_keep = min(dup['id1'], dup['id2'])
            id_remove = max(dup['id1'], dup['id2'])
            
            if analyzer.merge_duplicates(id_keep, id_remove):
                merged += 1
                print(f"‚úì –û–±—ä–µ–¥–∏–Ω–∏–ª {id_remove} ‚Üí {id_keep}")
        
        print(f"\n‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {merged} –ø–∞—Ä")
    
    elif choice == '4':
        # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        print("\nüöÄ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∞–∑—ã\n")
        
        # –®–∞–≥ 1: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        stats = analyzer.get_stats()
        print(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}")
        print(f"  –ë–µ–∑ —Ç–µ–≥–æ–≤: {stats['no_tags']}")
        print(f"  Legacy: {stats['legacy']}\n")
        
        if stats['by_category']:
            print("  –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, cnt in sorted(stats['by_category'].items(), key=lambda x: x[1], reverse=True):
                print(f"    ‚Ä¢ {cat}: {cnt}")
        
        print()
        
        # –®–∞–≥ 2: –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        if stats['no_tags'] > 0:
            print(f"‚è≥ –®–∞–≥ 1/2: –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ {stats['no_tags']} –∑–∞–ø–∏—Å–µ–π...")
            
            records = analyzer.get_all_records()
            no_tags = [(id, q, a, cat, tags) for id, q, a, cat, tags in records if not tags]
            
            for i, (id, q, a, cat, tags) in enumerate(no_tags, 1):
                if i % 10 == 0:
                    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(no_tags)}")
                
                analysis = analyzer.analyze_record(q, a)
                analyzer.update_record(id, analysis['category'], analysis['tags'])
            
            print(f"‚úÖ –¢–µ–≥–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã: {len(no_tags)}\n")
        
        # –®–∞–≥ 3: –î—É–±–ª–∏–∫–∞—Ç—ã
        print("‚è≥ –®–∞–≥ 2/2: –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        
        records = analyzer.get_all_records()
        duplicates = analyzer.find_duplicates(records, threshold=0.85)
        
        if duplicates:
            print(f"  –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(duplicates)}")
            
            merged = 0
            for dup in duplicates:
                id_keep = min(dup['id1'], dup['id2'])
                id_remove = max(dup['id1'], dup['id2'])
                
                if analyzer.merge_duplicates(id_keep, id_remove):
                    merged += 1
            
            print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {merged}\n")
        else:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç\n")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        final_stats = analyzer.get_stats()
        print(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {final_stats['total']}")
        print(f"  –° —Ç–µ–≥–∞–º–∏: {final_stats['total'] - final_stats['no_tags']}")
        print(f"  Legacy: {final_stats['legacy']}")
        
        print("\nüéâ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    
    elif choice == '5':
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n")
        
        stats = analyzer.get_stats()
        
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}")
        print(f"–ë–µ–∑ —Ç–µ–≥–æ–≤: {stats['no_tags']}")
        print(f"Legacy: {stats['legacy']}\n")
        
        if stats['by_category']:
            print("–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, cnt in sorted(stats['by_category'].items(), key=lambda x: x[1], reverse=True):
                pct = (cnt / stats['total'] * 100) if stats['total'] > 0 else 0
                print(f"  ‚Ä¢ {cat:12s}: {cnt:3d} ({pct:.1f}%)")
    
    else:
        print("–í—ã—Ö–æ–¥")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
