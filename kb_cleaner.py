#!/usr/bin/env python3
"""
Knowledge Base Cleaner & Importer v4.0
–û—á–∏—Å—Ç–∫–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∏–º–ø–æ—Ä—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ v4.0
"""

import json
import re
from typing import Dict, List, Tuple
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


class KBCleaner:
    """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –º—É—Å–æ—Ä–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    NOISE_PATTERNS = [
        r'–ì–ª–∞–≤–Ω–∞—è\s+',
        r'–ë—ã–ª–∞ –ª–∏ —ç—Ç–∞ —Å—Ç–∞—Ç—å—è –ø–æ–ª–µ–∑–Ω–æ–π\?.*?$',
        r'–î–∞\s+–ù–µ—Ç\s+–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏.*?$',
        r'–ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤:\s*\d+',
        r'Colizeum\s*\|?\s*HelpDeskEddy',
        r'(?:—Å—á–∏—Ç–∞—é—â–∏–µ|–∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç) —ç—Ç–æ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª –ø–æ–ª–µ–∑–Ω—ã–º:\s*\d+\s*–∏–∑\s*\d+',
        r'\s+-\s+Colizeum\s*\|.*?$',
        r'support\.colizeumarena\.ru.*?html',
        r'Colizeum_KB/.*?\.html',
    ]
    
    # –ù–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    NAVIGATION_PATTERNS = [
        r'^(?:Web –≤–µ—Ä—Å–∏—è CRM|–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –∫–æ–Ω—Å–æ–ª—å|–ö–ª–∏–µ–Ω—Ç—Å–∫–∞—è –æ–±–æ–ª–æ—á–∫–∞|–ü–ª–∞–Ω—à–µ—Ç)\s*',
        r'^(?:FAQ|–ù–∞—Å—Ç—Ä–æ–π–∫–∏|–ü—Ä–æ–±–ª–µ–º—ã|–°–µ—Ä–≤–∏—Å—ã|–û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ)\s*-?\s*',
    ]
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞
    QUESTION_ANSWER_SEPARATORS = [
        '–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?',
        '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:',
        '–î–ª—è —Ç–æ–≥–æ',
        '–ù–µ–æ–±—Ö–æ–¥–∏–º–æ',
        '–ü–µ—Ä–µ–π–¥–∏—Ç–µ',
        '–û—Ç–∫—Ä–æ–π—Ç–µ',
        '–ù–∞–∂–º–∏—Ç–µ',
        '–ó–∞–π–¥–∏—Ç–µ',
    ]
    
    def clean_text(self, text: str) -> str:
        """–û—Å–Ω–æ–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # –£–±–∏—Ä–∞–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.NOISE_PATTERNS:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)
        
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        text = re.sub(r'([\w\s]+)\s+\1+', r'\1', text)
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def extract_clean_question(self, raw_question: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
        # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã
        question = re.sub(r'\s*-\s*Colizeum.*$', '', raw_question, flags=re.IGNORECASE)
        question = re.sub(r'\s*\|\s*HelpDeskEddy.*$', '', question, flags=re.IGNORECASE)
        
        # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ - –¥–µ–ª–∞–µ–º –≤–æ–ø—Ä–æ—Å–æ–º
        if not question.strip().endswith('?'):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–º—ã—Å–ª
            if len(question.split()) <= 8 and not any(sep in question for sep in ['–ö–∞–∫', '–ß—Ç–æ', '–ì–¥–µ', '–ü–æ—á–µ–º—É']):
                question = f"–ß—Ç–æ —Ç–∞–∫–æ–µ {question}?"
        
        return self.clean_text(question)
    
    def extract_meaningful_answer(self, raw_answer: str, question: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        answer = self.clean_text(raw_answer)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞
        question_base = question.replace('?', '').strip()
        if answer.startswith(question_base):
            answer = answer[len(question_base):].strip()
        
        # –£–±–∏—Ä–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ (–±–æ–ª—å—à–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ–¥—Ä—è–¥)
        # –ü—Ä–∏–º–µ—Ä: "FAQ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ü—Ä–æ–±–ª–µ–º—ã –°–µ—Ä–≤–∏—Å—ã –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"
        words = answer.split()
        if len(words) > 10:
            # –ò—â–µ–º —É—á–∞—Å—Ç–æ–∫ –∏–∑ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–≥–ª–∞–≤–Ω—ã—Ö —Å–ª–æ–≤
            nav_end = 0
            for i in range(min(30, len(words))):
                word = words[i]
                # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏ –∑–∞–≥–ª–∞–≤–Ω–æ–µ - —ç—Ç–æ –Ω–∞–≤–∏–≥–∞—Ü–∏—è
                if len(word) <= 15 and (word[0].isupper() or word.isupper()):
                    nav_end = i + 1
                else:
                    # –í—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                    if len(word) > 4:
                        break
            
            if nav_end > 5:  # –£–¥–∞–ª—è–µ–º –µ—Å–ª–∏ > 5 –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–ª–æ–≤
                answer = ' '.join(words[nav_end:])
        
        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ - –Ω–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–π —á–∞—Å—Ç–∏
        for separator in self.QUESTION_ANSWER_SEPARATORS:
            if separator in answer:
                # –ë–µ—Ä—ë–º —Å —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞
                idx = answer.find(separator)
                answer = answer[idx:].strip()
                break
        
        # –£–±–∏—Ä–∞–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∏–∑ –Ω–∞—á–∞–ª–∞
        for pattern in self.NAVIGATION_PATTERNS:
            answer = re.sub(f'^{pattern}', '', answer, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        nav_prefixes = [
            r'^[–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+\s+',
            r'^FAQ\s+',
            r'^Web –≤–µ—Ä—Å–∏—è CRM\s+',
            r'^–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –∫–æ–Ω—Å–æ–ª—å\s+',
        ]
        for prefix in nav_prefixes:
            answer = re.sub(prefix, '', answer)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        answer = self.format_paragraphs(answer)
        
        return answer.strip()
    
    def format_paragraphs(self, text: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã"""
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        split_markers = [
            '–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã',
            '–ù–µ–æ–±—Ö–æ–¥–∏–º–æ',
            '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:',
            '–®–∞–≥',
            '–ü—Ä–∏–º–µ—Ä:',
            '–í–Ω–∏–º–∞–Ω–∏–µ:',
            '–í–∞–∂–Ω–æ:',
        ]
        
        for marker in split_markers:
            text = text.replace(f' {marker}', f'\n\n{marker}')
        
        # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        text = re.sub(r'(\d+)\)', r'\n\n\1)', text)
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()
    
    def extract_steps(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —à–∞–≥–æ–≤ –∏–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
        steps = []
        
        # –ò—â–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—É–Ω–∫—Ç—ã
        matches = re.finditer(r'(\d+)[).]\s*([^0-9]+?)(?=\d+[).]|\Z)', text, re.DOTALL)
        for match in matches:
            step_num = match.group(1)
            step_text = self.clean_text(match.group(2))
            if step_text:
                steps.append(f"{step_num}. {step_text}")
        
        return steps
    
    def improve_question(self, question: str, answer: str, category: str) -> str:
        """–£–ª—É—á—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π - —É–ª—É—á—à–∞–µ–º
        if question.startswith("–ß—Ç–æ —Ç–∞–∫–æ–µ") and len(question.split()) <= 5:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            answer_lower = answer.lower()
            
            if '–∫–∞–∫' in answer_lower[:50]:
                # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
                return question.replace("–ß—Ç–æ —Ç–∞–∫–æ–µ", "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç")
            elif '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞' in answer_lower[:50]:
                return question.replace("–ß—Ç–æ —Ç–∞–∫–æ–µ", "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å")
            elif '—É—Å—Ç–∞–Ω–æ–≤' in answer_lower[:50]:
                return question.replace("–ß—Ç–æ —Ç–∞–∫–æ–µ", "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å")
        
        return question
    
    def clean_record(self, record: Dict) -> Dict:
        """–û—á–∏—Å—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª—è
            raw_question = record.get('question', '')
            raw_answer = record.get('answer', '')
            category = record.get('category', 'general')
            tags = record.get('tags', [])
            source = record.get('source', '')
            
            # –û—á–∏—â–∞–µ–º –≤–æ–ø—Ä–æ—Å
            question = self.extract_clean_question(raw_question)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç
            answer = self.extract_meaningful_answer(raw_answer, question)
            
            # –£–ª—É—á—à–∞–µ–º –≤–æ–ø—Ä–æ—Å
            question = self.improve_question(question, answer, category)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            if not question or not answer:
                return None
            
            if len(answer) < 20:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
                return None
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–≥–∏
            if isinstance(tags, list):
                tags_str = ','.join(tags)
            else:
                tags_str = str(tags)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if category and category not in tags_str:
                if tags_str:
                    tags_str += f',{category}'
                else:
                    tags_str = category
            
            return {
                'question': question,
                'answer': answer,
                'category': category,
                'tags': tags_str.lower(),
                'source': 'colizeum_kb_cleaned',
                'confidence': 0.8  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∑–∞–ø–∏—Å–∏: {e}")
            return None


def load_jsonl(filepath: str) -> List[Dict]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ JSONL —Ñ–∞–π–ª–∞"""
    records = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                record = json.loads(line)
                records.append(record)
            except json.JSONDecodeError as e:
                logger.warning(f"–°—Ç—Ä–æ–∫–∞ {line_num}: –æ—à–∏–±–∫–∞ JSON - {e}")
    
    return records


def save_jsonl(records: List[Dict], filepath: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSONL"""
    with open(filepath, 'w', encoding='utf-8') as f:
        for record in records:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')


def main():
    import sys
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 kb_cleaner.py <input.jsonl> [output.jsonl]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else 'knowledge_cleaned.jsonl'
    
    print("=" * 60)
    print("  Knowledge Base Cleaner v4.0")
    print("=" * 60)
    print()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º
    print(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞: {input_file}")
    records = load_jsonl(input_file)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(records)} –∑–∞–ø–∏—Å–µ–π")
    
    # –û—á–∏—â–∞–µ–º
    print(f"\nüßπ –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π...")
    cleaner = KBCleaner()
    
    cleaned_records = []
    skipped = 0
    
    for i, record in enumerate(records, 1):
        if i % 50 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(records)}")
        
        cleaned = cleaner.clean_record(record)
        
        if cleaned:
            cleaned_records.append(cleaned)
        else:
            skipped += 1
    
    print(f"‚úÖ –û—á–∏—â–µ–Ω–æ: {len(cleaned_records)} –∑–∞–ø–∏—Å–µ–π")
    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped} –∑–∞–ø–∏—Å–µ–π")
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    print(f"\nüîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
    unique_records = []
    seen_questions = set()
    
    for record in cleaned_records:
        q_normalized = record['question'].lower().strip()
        if q_normalized not in seen_questions:
            unique_records.append(record)
            seen_questions.add(q_normalized)
    
    duplicates = len(cleaned_records) - len(unique_records)
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(unique_records)} –∑–∞–ø–∏—Å–µ–π")
    if duplicates > 0:
        print(f"‚ö†Ô∏è  –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates} –∑–∞–ø–∏—Å–µ–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {output_file}")
    save_jsonl(unique_records, output_file)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
    
    # –ü—Ä–∏–º–µ—Ä—ã
    print("\n" + "=" * 60)
    print("üìù –ü—Ä–∏–º–µ—Ä—ã –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π:")
    print("=" * 60)
    
    for i, record in enumerate(unique_records[:3], 1):
        print(f"\n–ó–∞–ø–∏—Å—å #{i}:")
        print(f"  –í–æ–ø—Ä–æ—Å: {record['question']}")
        print(f"  –û—Ç–≤–µ—Ç: {record['answer'][:150]}...")
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {record['category']}")
        print(f"  –¢–µ–≥–∏: {record['tags']}")
    
    print("\n" + "=" * 60)
    print("üéâ –ì–æ—Ç–æ–≤–æ!")
    print("=" * 60)
    print()
    print(f"–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∏–º–ø–æ—Ä—Ç –≤ v4.0")
    print(f"  python3 kb_importer.py {output_file}")


if __name__ == '__main__':
    main()
