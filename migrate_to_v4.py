#!/usr/bin/env python3
"""
Migration script v3.x ‚Üí v4.0
–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü, —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
"""

import sqlite3
import json
import sys
import os
from embeddings import EmbeddingService
from vector_store import VectorStore
from draft_queue import DraftQueue

DB_PATH = 'knowledge.db'
CONFIG_PATH = 'config.json'


def load_config():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞"""
    with open(CONFIG_PATH, 'r') as f:
        return json.load(f)


def create_draft_table(db_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤"""
    print("üìã –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã knowledge_drafts...")
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS knowledge_drafts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question TEXT NOT NULL,
            answer TEXT NOT NULL,
            category TEXT DEFAULT 'general',
            tags TEXT DEFAULT '',
            source TEXT DEFAULT '',
            confidence REAL DEFAULT 0.5,
            added_by INTEGER,
            reviewed_by INTEGER,
            status TEXT DEFAULT 'pending',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            reviewed_at TIMESTAMP
        )
    ''')
    
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_draft_status ON knowledge_drafts(status)')
    
    conn.commit()
    conn.close()
    
    print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ knowledge_drafts —Å–æ–∑–¥–∞–Ω–∞")


def get_all_knowledge(db_path):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è"""
    print("üìö –ó–∞–≥—Ä—É–∂–∞—é –∑–Ω–∞–Ω–∏—è –∏–∑ –ë–î...")
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT id, question, answer, category, tags
        FROM knowledge
        WHERE is_current = 1
    ''')
    
    records = cursor.fetchall()
    conn.close()
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(records)}")
    
    return records


def create_embeddings(records, embedding_service):
    """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π"""
    print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(records)} –∑–∞–ø–∏—Å–µ–π...")
    print("–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á-—ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    texts = []
    for id, question, answer, category, tags in records:
        combined = embedding_service.combine_qa(question, answer)
        texts.append(combined)
    
    # –ë–∞—Ç—á-—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embeddings = embedding_service.embed_batch(texts, show_progress=True)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embeddings)}")
    
    return embeddings


def build_vector_index(records, embeddings, vector_store):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"""
    print("\nüèóÔ∏è  –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    items = []
    
    for i, (id, question, answer, category, tags) in enumerate(records):
        items.append((
            id,  # kb_id
            embeddings[i],  # vector
            {
                'category': category,
                'tags': tags,
                'question': question[:100]  # –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            }
        ))
    
    # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
    vector_store.reindex(items)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫
    vector_store.save()
    
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(items)} –≤–µ–∫—Ç–æ—Ä–æ–≤")


def test_search(vector_store, embedding_service):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
    
    test_queries = [
        "–∫–∞–∫ –æ–±–Ω–æ–≤–∏—Ç—å –±–∏–æ—Å",
        "–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∫–ª—É–±",
        "—á—Ç–æ —Ç–∞–∫–æ–µ cls"
    ]
    
    for query in test_queries:
        print(f"\n  –ó–∞–ø—Ä–æ—Å: '{query}'")
        
        # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        query_vec = embedding_service.embed(query)
        
        # –ü–æ–∏—Å–∫
        results = vector_store.search(query_vec, top_k=3, min_score=0.5)
        
        if results:
            print(f"  –ù–∞–π–¥–µ–Ω–æ: {len(results)}")
            for r in results:
                print(f"    - kb_id={r['kb_id']}, score={r['score']:.3f}, cat={r['metadata'].get('category')}")
        else:
            print("  –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")


def main():
    print("=" * 60)
    print("   Migration v3.x ‚Üí v4.0 RAG Architecture")
    print("=" * 60)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(DB_PATH):
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω {DB_PATH}")
        sys.exit(1)
    
    if not os.path.exists(CONFIG_PATH):
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω {CONFIG_PATH}")
        sys.exit(1)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
    print("‚öôÔ∏è  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    config = load_config()
    print("‚úÖ –ö–æ–Ω—Ñ–∏–≥ –∑–∞–≥—Ä—É–∂–µ–Ω")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
    print("\nüöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤...")
    embedding_service = EmbeddingService(config['openai_api_key'])
    vector_store = VectorStore(dimension=1536)
    draft_queue = DraftQueue(DB_PATH)
    print("‚úÖ –°–µ—Ä–≤–∏—Å—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    
    # –®–∞–≥ 1: –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤
    print("\n" + "=" * 60)
    print("–®–∞–≥ 1: –¢–∞–±–ª–∏—Ü–∞ knowledge_drafts")
    print("=" * 60)
    create_draft_table(DB_PATH)
    
    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–Ω–∞–Ω–∏—è
    print("\n" + "=" * 60)
    print("–®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞–Ω–∏–π")
    print("=" * 60)
    records = get_all_knowledge(DB_PATH)
    
    if not records:
        print("‚ö†Ô∏è  –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞. –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        sys.exit(0)
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    print(f"\n‚ö†Ô∏è  –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–æ {len(records)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print(f"–ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${len(records) * 0.00002:.4f}")
    print(f"–í—Ä–µ–º—è: ~{len(records) // 100 + 1} –º–∏–Ω—É—Ç")
    
    confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ")
    if confirm.lower() != 'y':
        print("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ")
        sys.exit(0)
    
    # –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    print("\n" + "=" * 60)
    print("–®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print("=" * 60)
    embeddings = create_embeddings(records, embedding_service)
    
    # –®–∞–≥ 4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    print("\n" + "=" * 60)
    print("–®–∞–≥ 4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")
    print("=" * 60)
    build_vector_index(records, embeddings, vector_store)
    
    # –®–∞–≥ 5: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\n" + "=" * 60)
    print("–®–∞–≥ 5: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
    print("=" * 60)
    test_search(vector_store, embedding_service)
    
    # –ò—Ç–æ–≥
    print("\n" + "=" * 60)
    print("üéâ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    print("=" * 60)
    print()
    print("–°–æ–∑–¥–∞–Ω–æ:")
    print(f"  ‚úÖ –¢–∞–±–ª–∏—Ü–∞ knowledge_drafts")
    print(f"  ‚úÖ {len(embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    print(f"  ‚úÖ –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS")
    print(f"  ‚úÖ –§–∞–π–ª—ã: vector_index.faiss, vector_metadata.pkl")
    print()
    print("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
    print("  1. –û–±–Ω–æ–≤–∏—Ç–µ bot.py –¥–æ v4.0")
    print("  2. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ: systemctl restart club_assistant")
    print()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
